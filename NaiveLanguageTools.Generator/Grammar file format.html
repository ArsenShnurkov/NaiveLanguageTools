<html><head>
<title>NLT grammar file format</title>
<style>
pre {background-color:gainsboro; padding:0.5em;}
h2 {background-color:midnightblue;color:white; margin:1.5em 0 0.5em 0;padding:0.35em 0.25em 0.35em 2em}
</style></head>
<body>

<h1>NLT grammar file format</h1>

<p>The grammar file contains of several sections in arbitrary order:</p>
<ul>
<li><a href="#using">using (optional)</a>,</li>
<li><a href="#types">types (optional)</a>,</li>
<li><a href="#terminals">terminals (optional)</a>,</li>
<li><a href="#namespace">namespace</a>,</li>
<li><a href="#options">options</a>,</li>
<li><a href="#lexer_type">lexer type name</a>,</li>
<li><a href="#parser_type">parser type name</a>,</li>
<li><a href="#tokens_type">tokens type name</a>,</li>
<li><a href="#lexer_patterns_type">lexer named patterns type name (optional)</a>,</li>
<li><a href="#states">states (optional)</a>,</li>
<li><a href="#scanning_rules">scanning rules</a>,</li> 
<li><a href="#precedence">precedence (optional)</a>,</li>
<li><a href="#parsing_rules">parsing rules</a>.</li>
</ul>

NLT uses C-like comments (single line and multi line). Multi line comments can be nested.

A convention good as any other — terminals are written in upper case (like <tt>CLASS</tt>), non-terminals are written in lower case
(like <tt>statement</tt>).

<h2 id="using">Using section</h2> <!----------------------------------------------------------------------------------------->

<p>Example:</p>
<pre>
using 
  System
  System.Collections.Generic
end
</pre>

Included namespaces are whitespace-separated.

<h2 id="types">Types section</h2> <!----------------------------------------------------------------------------------------->

<p>In each line you give comma-separated symbols (terminals or non-terminals) and their typename. Ech line is ended with semicolon.<br/>
Defining the type of the symbol is useful to avoid casting in parsing actions.</p>

<p>Example:</p>
<pre>
types
  expression Expression;
  ns_body,function_definition TreeNode; // comma-spaced
end
</pre>

<h2 id="terminals">Terminals section</h2> <!----------------------------------------------------------------------------------------->

<p>This section is used to add terminals otherwise not visible to NLT generator — for example terminal used in external
methods. Terminals are whitespace-separated.</p>

<p>Example:</p>
<pre>
terminals
  CONST_CHAR
  CONST_STR
end
</pre>

<p>It is guaranteed that generated tokens start with <tt>Error</tt> meta token, followed by <tt>EOF</tt> and
terminals given in this section will preserve the order.</p>

<h2 id="namespace">Namespace section</h2> <!----------------------------------------------------------------------------------------->

<p>It defines the namespace of the symbols, lexer and parser types, example:</p>
<pre>
namespace Skila.Frontend;
</pre>

<h2 id="lexer_type">Lexer type name section</h2> <!----------------------------------------------------------------------------------------->

<p>It defines the class name of the lexer, example:</p>
<pre>
lexer SkilaLexer;
</pre>

<p>The method responsible for creating lexer can be generated as <tt>override</tt>:</p>

<pre>
lexer override SkilaLexer;
</pre>

<p>By default, the generated class inherits from <tt>Object</tt> but it can be changed:</p>

<pre>
lexer SkilaLexer : SkeletonLexer&lt;SymbolConstants&gt;;
</pre>

<p>One can add an optional part of C# code:</p>

<pre>
lexer SkilaLexer {
	int nestCounter; // real C# code
};
</pre>

<h3>Factory function parameters</h3>

<p>It is possible to declare parameters for factory function — it looks like constructor in Scala, however those are parameters for
function, not a constructor:</p>

<pre>
lexer SkilaLexer(bool exact);
</pre>

<h2 id="parser_type">Parser type name section</h2> <!----------------------------------------------------------------------------------------->

<p>It is built exactly as <tt>lexer</tt> section just using <tt>parser</tt> keyword instead, for example:</p>

<pre>
parser ParserFactory(string filename) : SkeletonParser
{
	StringBuilder builder;
};
</pre>

<h2 id="tokens_type">Symbol type name section</h2> <!----------------------------------------------------------------------------------------->

<p>It defines the type name (enum) of the symbols. Two symbols — <tt>EOF</tt> and <tt>Error</tt> — are automatically generated by NLT, example:</p>

<pre>
tokens TokenEnum;
</pre>

<p>It is rare case, but nevertheless — sometimes tokens represented as constant integers are needed (instead of <tt>enums</tt>). In such case
add keyword <tt>int</tt> after <tt>tokens</tt>:</p>

<pre>
tokens int TokenConstants;
</pre>

<h2 id="lexer_patterns_type">Lexer named patterns class name</h2> <!----------------------------------------------------------------------------------------->

<p>When it is needed one can set a class name where generator should place lexer named patterns (and also a directory for it):</p>

<pre>
patterns Skila.Language.TreeConstants;
</pre>

<p>Above we have only class name with namespace, below there is also a directory for a class file given:</p>

<pre>
patterns Skila.Language.TreeConstants "../myDir";
</pre>

<p>Please note generator will populate the patterns class only with the lexer patterns marked with <tt>var</tt>.</p>

<h2 id="options">Options section</h2> <!----------------------------------------------------------------------------------------->

<p>You can specify options how your lexer/parser is built:<br/>
<pre>
options mre;
</pre>
</p>

<p>Each option can be preceeded with <tt>+</tt> or <tt>-</tt> sign to switch on/off given option. Plus sign can be ommited.</p>

<p>Usage of precompiled multi regular expression engine is controlled via <b>mre</b> option (default: on). 
It gives approximately *2 speed-up in lexer execution. MRE supports most of the syntax of standard regexes supported by .Net — exceptions are:
<ul>
<li>^ — matches the beginning of the input</li>
<li>$ — matches the end of the input</li>
<li>? — as non-greedy switch</li>
<li>(?:pattern) — non-capturing match</li>
<li>(?=pattern) — positive lookahead search</li>
<li>(?!pattern) — negative lookahead search</li>
<li>\b — word boundary</li>
<li>\B — nonword boundary</li>
<li>\cx — control character</li>
<li>\num — backreference</li>
<li>\n — octal value or backreference</li>
<li>\nm — as above </li>
<li>\nml — octal value</li>
</ul></p>

<p>MRE supports parentheses for grouping, but not for capturing (i.e. you cannot reference a group). MRE is not fully
compatible with .Net regular expressions, for example for MRE pattern <tt>A{</tt> is invalid (left brace opens repetition counter), 
.Net RE framework on the other hand does not complain.</p>

<h2 id="states">Lexer states section</h2> <!----------------------------------------------------------------------------------------->

<p>It defines the type name (enum by default) of the states and the states themselves — first identifier given is the type name, the rest are the states.<br/>
The states with asterisk prefix are the default ones — one cannot decorate the scanning rules with them.
</p>

<b>Example</b>
<pre>
states StateEnum
  *INIT
  
  STR
  COMMENT
end
</pre>

<p>When <tt>int</tt> is required instead of <tt>enum</tt>:</p>

<pre>
states int StateEnum
  *INIT
  ...
end
</pre>

<h2 id="scanning_rules">Lexer rules section</h2> <!----------------------------------------------------------------------------------------->

<p>Lexer picks the longest matches, out of them it picks the first one (counting from top). It is an error of having no match. 
The patterns are defined using strings or regular expressions.</p>

<h3>String pattern</h3>
<p>The simplest form — string pattern, no state is given, thus default is used, just symbol is given to be returned:</p>
<pre>
scanning
  "ref" -> PARAM_REFERENCE;
end
</pre>

<p>For the rest of the examples let assume they are already within <tt>scanning-end</tt> block.</p>

<h3>Win fast</h3>

<p>Consider the rules (using regular expressions):</p>

<pre>
/%%rem/ -> BLOCK_COMMENT;
/%%.*/ -> SINGLE_COMMENT;
</pre>

<p>and the input “<tt>%%rem something</tt>”. The second rule will give longer match and it will win. It is possible to force the first rule to win this
competition:</p>

<pre>
! /%%rem/ -> BLOCK_COMMENT;
  /%%.*/ -> SINGLE_COMMENT;
</pre>

<p>Exclamation mark as the first symbol of the rule says this rule will win no matter how long the text match is. Once such priority rule is triggered
it can only expand its match but no other rule will win (for that match).</p>

<h3>Adding value</h3>
<p>Still string pattern, BOOL_CONST will be returned as recognized token, and the expression (!) as the value for it:</p>
<pre>
"true" -> BOOL_CONST, true;
</pre>

<h3>Expression vs. statement</h3>

<p>When the expression is more elaborate and confuses NLT generator, surround it with the braces:</p>

<pre>
"true" -> BOOL_CONST, { true };
</pre>

<p>Just remember there is difference between expression (above) and statement (below; incorrect) — note the extra semicolon:</p>

<pre>
"true" -> BOOL_CONST, { true; };
</pre>

<p>This will lead to invalid C# because there is no such statement. If the statement is needed, it has to be in proper form, for example:</p>

<pre>
"true" -> BOOL_CONST, { $value = true; };
</pre>

<h3>Token, value and target state</h3>

<p>There is even more elaborate version allowing to specify 3 entities:</p>

<pre>
"options" -> SYM_OPTIONS, Options.CreateSection(), +ST_OPTIONS;
</pre>

<p>This rule will return token <tt>SYM_OPTIONS</tt> with content set <tt>Options.CreateSection()</tt> at the same time pushing 
new state <tt>ST_OPTIONS</tt>. You can skip the state (as previous example shows) or you can skip the code or you can skip both of them. In case there is
some ambiguity when passing just 2 elements, whether the second one is the value or the target state, keep the comma:</p>

<pre>
"options" -> SYM_OPTIONS, +X, ;
</pre>

<p>In the example above it is clear <tt>+X</tt> is content value, not the target state for lexer.</p>

<p>In order to pop state from the stack, pass as state bare <tt>-</tt> (minus) sign.</p>

<h3>Regex pattern</h3>
<p>Because it is basic form (arrow makes a basic form) there is still just an expression in braces. Note pseudo-variable <tt>$text</tt>:</p>
<pre>
/[A-Za-z_][A-Za-z_0-9]*/ -> IDENTIFIER, IdentifierSymbol.Create($text);
</pre>

<p>Unlike string patterns which are processed in string mode (in C# <tt>""</tt>), regex patterns are processed in verbatim string mode (in C# <tt>@""</tt>). 
For example in order to pass character question mark to regex one enters <tt>/\?/</tt>.</p>

<h3>Escape sequences</h3>

<p>Unlike C#, NLT requires that escape sequences are valid (both string and regex ones). 
For example regex <tt>/\=/</tt> is treated as an error while C# treats it as 2 characters.</p>

<h3>Case insensitive patterns</h3>
<p>By default both patterns are case sensitive — by appending letter "i" at the end of the pattern (string or regex) one can make the pattern
case insensitive:</p>
<pre>
"let"i -> LET;
</pre>


<h3>Statement block</h3>
<p>String pattern with code as list of statements instead of single expression — here with no direct token, 
entire code is defined inside braces:</p>
<pre>
"\"" -> { string_buf = new StringBuilder();
          string_error = false;
        }, +RAW_STR; // push the state
</pre>

<h3>Differece between the statements and expression</h3>

<p>Code passed as statements has the ability of not setting the token and also the value associated with the token. Compare:</p>

<pre>
"let" -> LET, Identifier.Create($text); // code as expression
"let" -> { $token = Symbols.LET; $value = Identifier.Create($text); }; // same as above with code as statement 

// cutting out the value
"let" -> LET; 
"let" -> { $token = Symbols.LET; }; 

// cutting out the token
"let" -> { }; // the only way
</pre>

<h3>Explicit state</h3>
<p>The state is given explictly — here <tt>COMMENT</tt>:</p>
<pre>
COMMENT /.|\r/ -> { };
</pre>

<h3>Multi state rules</h3>
<p>This rule applies in two states	(<tt>RAW_STR</tt> or <tt>STR</tt>). In code pseudo-variable <tt>$match</tt> is used — it holds properties:
<tt>Text</tt>, <tt>Value</tt>, <tt>Token</tt> and <tt>Coordinates</tt>:</p>
<pre>
RAW_STR STR "\"" -> { if (!string_error)
                        validateString($match, false);
                    }, -; // pop the state
</pre>

<p>There are two ways of mixing default states in. Assuming we have set <tt>INITX</tt> and <tt>INITY</tt> as default states:</p>

<pre>
INITX INITY OPTIONS_SECTION "," -> COMMA;
</pre>

<p>or shorter:</p>

<pre>
* OPTIONS_SECTION "," -> COMMA;
</pre>

</h3>Context</h3>

<p>Context is built upon already recognized symbols — in this case "id" will be recognized as <tt>IDENTIFIER</tt> only if we just recognized <tt>ARROW</tt>
and <tt>COMMA</tt> (as a sequence, not a set):</p>

<pre>
"id" (ARROW COMMA) -> IDENTIFIER;
</pre>

<p>Please note we require that <tt>ARROW</tt> occurred before <tt>COMMA</tt>.</p>

<p>One can pass several alternative contexts:</p>

<pre>
"id" (ARROW COMMA | DOT EXCL_MARK) -> IDENTIFIER;
</pre>

<h3>Altering the stream of tokens</h3>
<p>It is possible to return extra tokens in single action using method <tt>PrependToken/AppendToken</tt> 
and on the other hand it is possible to remove previously created ones — see below:
<pre>
"if"(ELSE) -> {
                lexer.RemoveTokens(1);
                $token = TokenEnum.ELSIF;
              };
</pre>

<p>The methods <tt>RemoveTokens</tt> returns removed tokens. It cannot remove freshly yielded tokens, it operates only on past ones.</p>

<h3>Before/after tokens</h3>

<p>It is also possible to add extra tokens using lexer methods <tt>PrependToken</tt> and <tt>AppendToken</tt> — the order of the execution 
is only relevant for given group:</p>

<pre>
"order" -> {
	          lexer.AppendToken(TokenEnum.Fourth);
	          lexer.AppendToken(TokenEnum.Fifth);
	          lexer.PrependToken(TokenEnum.First);
	          lexer.PrependToken(TokenEnum.Second);
              $token = TokenEnum.Third; // can be only one
           };
</pre>

<h3>Supported pseudo-variables</h3>
<p>Instead of using <tt>$match.Value</tt> (or other mentioned properties with an exception for <tt>$pos</tt> which stands for shortcut <tt>Coordinates.FirstPosition</tt>
holding filename, line and column, and for <tt>$coords</tt> which is abbreviation of <tt>Coordinates</tt> field) you can use directly <tt>$value</tt> and <tt>$text</tt> pseudo-variables:</p>
<pre>
"*/" -> { $value = "Unmatched */"; 
          $token = TokenEnum.Error; 
        };
</pre>

<p>There is unrelated to <tt>match</tt>, pseudo-variable <tt>state</tt> which is shortcut for <tt>lexer.State</tt>.</p>

<h3>Grouping for state</h3>
<p>Several rules for the same states — enclose the rules in parentheses and put states in front (no states inside):</p>
<pre>
STR CHAR (
            "\\b"  -> { string_buf.Append("\b"); };
            "\\t"  -> { string_buf.Append("\t"); };
         );    
</pre>

<h3>Nesting states groups</h3>

<p>One can nest groups of lexer rules for the same states. Previous example can be rewritten as:</p>

<pre>
STR (
  CHAR (
         "\\b"  -> { string_buf.Append("\b"); };
         "\\t"  -> { string_buf.Append("\t"); };
       );    
    );
</pre>

<h3>Named patterns</h3>

<p>If pattern is used several times (or for other reasons) one can introduce named pattern as in following example:</p>

<pre>
whitespaces = /[ \r\n\f\t\u000b]+/;

IN_CODE_MACRO whitespaces (LMACRO) -> { };
CODE_BLOCK whitespaces -> { str_buf.Append($text); };
</pre>

<p>It is possible to “export” the pattern as field in generated class — preceed the definition of the pattern with keyword <tt>var</tt>:</p>

<pre>
var whitespaces = /[ \r\n\f\t\u000b]+/;
</pre>

<h3>Combining patterns</h3>

<p>It is possible to combine patterns — the only condition is type (string/regex) and case sensitivity have to be the same.</p>

<pre>
id = /[A-Za-z_][A-Za-z_0-9]*/;

/\$/ + id -> CODE_PLACEHOLDER, $text.Substring(1);
</pre>

<h3>EOF</h3>
<p>Special rule for EOF case (end of the file) — no state, no pattern, just action (or just token as in simple form):</p>
<pre>
%EOF -> { if (lexer.IsValidEofState)
            $token = TokenEnum.EOF;
          else  
          {
            $value = "Invalid state at EOF";
            $token = TokenEnum.Error;
          }
        };
</pre>
			
<p>Presented action is set as default on-EOF action (if it is all you need do not define EOF rule).</p>

<h3>Handling errors</h3>
<p>By default setting <tt>Error</tt> stops scanning, but if the value of the symbol is set to <tt>true</tt>, scanning will be continued. 
For example you can not accept tab characters but since it is a minor error you can still process the file:</p>
<pre>
"\t" -> Error, true;
</pre>

<h2 id="precedence">Parsing precedence section</h2> <!----------------------------------------------------------------------------------------->

<p>This section defines precedence of operators for parser. The order of the lines is from the least important precedence rule to the most important one.</p>

<h3>Operator mode</h3>
<p>The most basic mode — you just specify associativity and at least one symbol:<br/>

<pre>
precedence
  op right ASSIGN;
  op none NOT;
end
</pre>
</p>

<p>For the rest of the examples let assume they are already within <tt>precedence-end</tt> block.</p>

<h3>Example</h3>
<p>Here forking is applied on <tt>DOUBLE_COLON</tt>:</p>
<pre>
op try DOUBLE_COLON;
</pre>

<h3>Example</h3>
<p>Shift/reduce resolving during parsing. Here force shift when there is a conflict 
between <tt>fq_identifier</tt> (reduce production) and <tt>expression</tt> (shift production) on incoming symbol (lookahead) <tt>DECL_ASSIGN</tt>:</p>
<pre>
rs shift DECL_ASSIGN fq_identifier expression;
</pre>

<h3>Same rules for various inputs</h3>
<p>If there are several identical rules with just different incoming symbol (lookahead) we can merge them as one:<br/>
<pre>
rs shift (DECL_ASSIGN ASSIGN) fq_identifier expression;
</pre>
Note the parentheses around multiple lookaheads.
</p>

<h3>Example</h3>
<p>In the same way reduce-reduce conflicts can be resolved. Fork (try) when there is a conflict 
between <tt>statement_list</tt> and <tt>expression</tt> on incoming symbol (lookahead) <tt>BOOL_CONST</tt>. Forking is the only possible way to
resolve reduce-reduce conflict except of rewriting the grammar.</p>
<pre>
rr try BOOL_CONST statement_list expression;
</pre>

<p>Please note: setting high priority for reduce-reduce conflict resolution can override reduce-shift resolution.</p>

<p>For shift/reduce conflict, there is even more detailed pattern. One can define operators which should be present
on stack for reduce move.</p>

<h3>Example:</h3>

<pre>
rs shift LANGLE expression(AND) expression;
</pre>

<p>This rule tells NLT to shift when there is a conflict between reduce move having <tt>AND</tt> operator on stack and shift move (another <tt>expression</tt>) 
with left angle bracket (<tt>LANGLE</tt>) coming from input (lookahead symbol).</p>

<h3>Solving multiple conflicts</h3>

<p>When dealing with multiple conflicts you could rewrite the same precedence rules grouping them around input symbols or around productions. 
You should do the former, because it is the input which causes the conflict. For example consider:</p>

<pre>
rs try (BASE NEW TEST PARTIAL) statement_list named_expression terminated_statement;
rs try (BASE NEW TEST GET SET) statement_list sink_identifier;
rs try (PARTIAL) statement_list terminated_control;
</pre>

<p>and:</p>

<pre>
rs try (BASE NEW TEST) statement_list named_expression terminated_statement sink_identifier;
rs try (PARTIAL) statement_list named_expression terminated_statement terminated_control;
rs try (GET SET) statement_list sink_identifier;
</pre>

<p>They express the same meaning (for a human) but only the latter works. To see this, notice only the latter answers the question what to do with
<tt>PARTIAL</tt>. The former is nicely grouped, but does not give definitive answer, because it has two rules for conflict on <tt>PARTIAL</tt>.</p>

<h3>Grouping rules with the same precedence</h3>

<p>Write your rules with comma as separator, for example:</br>

<pre>
rs try STATIC opt_function_mod class_field,
  rs try STATIC opt_class_mod class_field,
  rr try STATIC opt_function_mod opt_class_mod;
</pre>

Above group of rules solves the shift/reduce-reduce/reduce conflict.</p>

<p>Note <tt>right</tt> is equivalent to <tt>shift</tt>, and <tt>left</tt> is equivalent to <tt>reduce</tt>. One can use 
the names which are more clear to oneself.</p>

<h3>Operator table</h3>

<p>Basic operator mode lacks proper control, reduce-shift rules are tiresome to write. If there is conflict between the same production but 
on different symbol we can use operator table:</p>

<pre>
rs (
    left PLUS
    left MINUS

    left MUL
    left DIV
    
    right POWER
   ) expression;
</pre>

<p>The above rule is for <tt>expression-expression</tt> conflict — for different symbols, like for example <tt>PLUS-DIV</tt>, <tt>DIV</tt> triggers
reduce first, because it has higher priority. For the same symbol conflict, say <tt>MUL-MUL</tt>, the action is performed according to given associativity, 
in case of <tt>MUL</tt> — left.</p>

<h2 id="parsing_rules">Parsing rules section</h2> <!----------------------------------------------------------------------------------------->

<p>The are two ways of controlling the
parsing process. One can throw exception — <tt>ParseControlException</tt> — on rather serious error or return <tt>RichParseControl</tt>
object with warning information.</p>

<p>Parsing rules are contained within <tt>parsing-end</tt> block. Let assume all presented rules are already in such block.<br/>
In general each production has the form of non-terminal on left, arbritrary symbols on right plus action (code) per production. 
Actions are written in braces.</p>

<h3>Alternatives</h3>
<p>Here are two alternatives:</p>
<pre>
data_type -> "struct"
             { DataTypeEnum.ValueType }
           | CLASS
             { DataTypeEnum.ReferenceType }
           ;  
</pre>

<p>In the first alternative we use literal as terminal, in the second we use directly terminal (defined in lexer rules). The second 
approach is recommended but the first one may be handy when testing parser or writing really small one.</p>

<h3>Expression vs. statement</h3>

<p>Same principles apply as with code for lexer rules — either code is single expression (as above) or it has to make proper statements (below):</p>

<pre>
data_type -> "struct"
             { return DataTypeEnum.ValueType; }
           | CLASS
             { return DataTypeEnum.ReferenceType; }
           ;  
</pre>


<h3>Empty matches</h3>

<p>Empty match can be expressed in several ways — compare them (empty match is defined in the first line). No visual cues at all:</p>

<pre>
opt_context -> { } 
             | LPAREN list RPAREN { $list }
             ;
</pre>

<p>With comment as visual indicator:</p>

<pre>
opt_context -> /* empty */ { }
             | LPAREN list RPAREN { $list }
             ;
</pre>

<p>Meta-symbol <tt>%empty</tt> is used — the meaning is exactly the same as before. This is the recommended way:</p>

<pre>
opt_context -> %empty { }
             | LPAREN list RPAREN { $list }
             ;
</pre>

<h3>Named symbols</h3>

<p>One can name symbol, so it can be used in code. Note the casting — type name associated with <tt>namespace_list</tt> was not defined:</p>
<pre>
program -> list:namespace_list 
           { new Program(currCoords(), (Namespaces)list) }
         ;
</pre>

<h3>Recursive rules</h3>

<p>Recursive rules have to be explicitly marked by user — not for NLT of course, but as visual cue that the rule is recursive:</p>

<pre>
@expr -> e1:expr "+" e2:expr { new Plus(e1,e2) };
</pre>

<p>One can always consult the reports and find out the full path how given symbol became recursive one. This helps finding unwanted
holes in the syntax.</p>

<h3>Production type</h3>
<p>Casting is not required if <tt>IDENTIFIER</tt> was defined:</p>
<pre>
ex_identifier -> id:IDENTIFIER 
                 { id }
               ;
</pre>

<p>If one passes just single object without any modification (as shown above) the code block is optional, because generator can infer the object. Examples:

<pre>
ex_identifier -> IDENTIFIER // no code block, IDENTIFIER is returned
               | LPAREN IDENTIFIER RPAREN // error, impossible to infer which object to return
               | LPAREN _:IDENTIFIER RPAREN // OK, the name serves as indication which object to return
               | atom+ // OK, it is single object
               ;
</pre>

<p>Adding empty block surpresses guessing:

<pre>
ex_identifier -> IDENTIFIER  { }; // empty code block, null will be returned as object value
</pre>

<h3>Local type definition</h3>
<p>The type name (<tt>Argument</tt>) associated with symbol (<tt>named_expr</tt>) is given in parsing production instead of types section:</p>
<pre>
named_expr Argument -> expr:expression
                       { new Argument(currCoords(), expr) }
                       ;
</pre>

<h3>Macros</h3>
<p>Note the optional elements — marked with question mark and set of symbols — enclosed in brackets, only one element from the set can be used.<br/>
One controls optional element directly in code (see next production), or use macro expansion:
<ul>
<li><tt>$(argument?)</tt> — true if present, false otherwise,</li>
<li><tt>$(argument)</tt> — value of the argument if present, <tt>null</tt> otherwise,</li>
<li><tt>$(argument : fallback_value)</tt> — if present, argument is used, if not fallback value,</li>
<li><tt>$(argument : value1 : value2)</tt> — if argument is present, <tt>value1</tt> is used, if not — <tt>value2</tt>.</li>
</ul>  
Case<br/> 
<pre>$(argument : argument.property : value2)</pre>
can be shortened to<br/> 
<pre>$(argument.property : value2)</pre></p>
<pre>
formal_param -> attr:param_attr? colon:COLON? [ pref:PARAM_REFERENCE sink:SINK exc:EXCLAMATION ]? name:IDENTIFIER typename:type_signature
                { new FunctionParameter(currCoords(), $(colon : FunctionParameter.NamedEnum.Yes : FunctionParameter.NamedEnum.No),
                            $(attr.Value : ValueMutAttrEnum.Constant),
                            $(sink : ValueUsageEnum.CanBeIgnored : ValueUsageEnum.UseRequired), 
                            name,
                            typename
		              .SetRefMutable($(exc))
                              .SetPassViaReference($(pref))) 
                }
              ;
</pre>

<h3>Standard placeholders</h3>

<p>In parser section one can use <tt>$pos</tt> and <tt>$coords</tt> placeholders which have very similar meaning as in lexer section —
<tt>parser.Coordinates.FirstPosition</tt> (holding filename, line and column) and <tt>parser.Coordinates</tt> (holding <tt>FirstPosition</tt> and
<tt>LastPosition</tt>).</p>

<h3>Placeholders</h3>
<p>Naming each symbol can be tedious, so in simple productions one can use placeholders. Instead of:</p>

<pre>
dict_list -> (COMMA- d:dict)+ { d };
</pre>

<p>we can write:</p>

<pre>
dict_list -> (COMMA- dict)+ { $dict };
</pre>

<p>Placeholder is just a symbol name with “$” prefix. Note, that placeholder has to be uniquely bound to the symbol and you can use placeholders
only for anonymous symbols.</p>

<h3>Optional sequence</h3>
<p>Note the optional sequence — enclosed in parentheses, unlike set it works as everything (in given order) or nothing. Here the control of the optional
elements are manual (not recommended):</p>
<pre>
named_expr -> pref:PARAM_REFERENCE? ( name:IDENTIFIER COLON )? exc:EXCLAMATION? expr:expression
              { new Argument(currCoords(), (name??IdentifierSymbol.NoIdentifier), 
                (exc==null?ValueMutAttrEnum.Constant:ValueMutAttrEnum.Variable),pref!=null,expr) }
            ;
</pre>

<h3>Combined sequence</h3>
<p>There is another kind of groups — “altogether” group. It produces each element from a group like from the set group plus all elements as in sequence group.
In this case:<br/>
<ul>
<li><tt>type_signature</tt></li>
<li><tt>ASSIGN expression</tt></li>
<li><tt>type_signature ASSIGN expression</tt></li>
</ul></p>
<pre>
command ->  VAR name:IDENTIFIER &lt; type:type_signature , ASSIGN expr:expression &gt;
            { new VariableDeclaration(currCoords(),
                  name,
                  $( type : TypeNameSignature.NoTypeName),
                  $( expr : new NoExpr(currCoords()))) 
            }
          ;
</pre>

<h3>Repetitions</h3>
<p>Symbols, sets and sequences can be multiplied (with operators <tt>*</tt> or <tt>+</tt>) — instead of having just an object in the action, 
entire list is built by NLT:</p>
<pre>
namespace_list -> ns:namespace_+ 
                  { new Namespaces(currCoords(),ns) };
</pre>

<p>For a sequence two-or-more symbols can be used — <tt>++</tt> — as in following example:</p>

<pre>
seq_list -> (SPACE n:node)++ { new Seq(" ",n) };
</pre>

<p>It is not a repetition per se, because it does not multiply anything, but it belongs in this category 
anyway — optional entity (marked with <tt>?</tt>):</p>

<pre>
tuple_param FunctionParameter -> name:param_name? colon:COLON? type_desc:type_description 
                                 { ... };                                   
</pre>

<p>We just indicated that “name” part as well “colon” is optional — i.e. it can be present or not (if not, <tt>null</tt> value is assigned for it).</p>

<p>There is also a combo repetition mode (<tt>+?</tt>):</p>

<pre>
property Property -> mod? DEF formal_opt_list function_outcome class_field+? accessor* end_def 
                     { ... };
</pre>

<p>In the example above we say we expect a non-empty list of class fields or <b>no</b> list at all (<tt>null</tt>). 
Please pay attention to this little detail — <tt>*</tt> means a list (always) with zero or more elements, with <tt>+?</tt> you will never get a list
with zero elements, you will get <tt>null</tt> instead. The benefit of the former is your code is more concise (no corner cases), however
the latter avoids grammar conflicts (thus the obvious advice — if you get any error because of reducing empty lists the first thing to try out is replacing
<tt>*</tt> with <tt>+?</tt>).</p>

<h3>Naming elements within repeated group</h3>
<p>Only one element can be named per repeated group — the only exception is a sequence which can take multiple named symbols:</p>
<pre>
seq_list -> (sp:space n:node)++ { new Seq(sp,n) };
</pre>

<h3>Naming a set</h3>
<p>Having a set with elements expressing the same type it is useful to give them the same name — one should name entire group, not individual elements of the set (it works
also without multiplication):</p>
<pre>
ns_body -> feat:[type function_definition]+
          { new Features(currCoords(),feat) };
</pre>

<h3>Initial exclusion</h3>
<p>Multiplication of the sequence. Parameters in programming language Skila are comma-separated, but making entire sequence repeated would mean the list of the parameters starts
with comma. To make a list properly separated with given symbol it has to be initially excluded — the minus character does that, 
indicates exclusion of the symbol from the first repetition:</p>
<pre>
formal_list -> (COMMA- formal:formal_param)*
               { new FunctionParameters(currCoords(),formal) }
               ;
</pre>

<h3>Action type inference</h3>
<p>If action starts with constructor call there is no need to define the type explictly, because NLT is capable of inferring it:</p>
<pre>
rich_list -> (COMMA- s:STRING)*
             { new RichList(currCoords(),s) }
             ;
</pre>

<p><tt>rich_list</tt> becomes for NLT of type <tt>RichList</tt>.</p>

<h3>Production decoration</h3>
<p>Any production can be decorated with arbitrary identifier (it does not have to be a symbol):</p>
<pre>
@expr -> %mark(addition) e1:expr PLUS e2:expr
	{ e1+e2 };
</pre>
<p>If the decoration is the same as the symbol used in production, like here:</p>
<pre>
@expr -> %mark(PLUS) e1:expr PLUS e2:expr
	{ e1+e2 };
</pre>
<p>The symbol can be accented to make a decoration (still being treated as regular symbol):</p>
<pre>
@expr -> e1:expr ^PLUS e2:expr
	{ e1+e2 };
</pre>

<h3>Decoration constraints</h3>
<p>If the priority of productions cannot be defined in-advance, it can be done while parsing using decoration constraints:</p>
<pre>
@expr -> e1:expr #PLUS MULT e2:expr #PLUS
	{ e1*e2 };
</pre>
<p>Such rule states that multiplication does not take PLUS-decorated expression as left or right expression. Thus making text “1+2*3+2” parsed
as “(1+2)*(3+2)” impossible.</p>

<p><small><i>NLT grammar file format — end of the document.</i></small></p>

</body>
</html>
